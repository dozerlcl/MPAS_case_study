{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 954 ms, sys: 267 ms, total: 1.22 s\n",
      "Wall time: 1.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import dask\n",
    "# import cmaps\n",
    "\n",
    "# 国内政区图的绘制\n",
    "# Load the border data, CN-border-La.dat is download from\n",
    "# https://gmt-china.org/data/CN-border-La.dat\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.io.shapereader as shpreader\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.patches as mpatches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 进行风和比湿拆分的绘制\n",
    "\n",
    "2021.09.25\n",
    "\n",
    "使用shumflux中进行前处理的脚本，将VR,RCM,OBS读作相同坐标的变量，之后再使用dict进行变量区域的筛选，筛选出850hPa风以及比湿之后放入REFERENCE中待下一步绘制\n",
    "\n",
    "原本在49.19的绘图服务器上进行计算，但是有占用，IO大文件速度太慢。在存储数据的服务器进行NC变量的拆分处理\n",
    "\n",
    "2021.10.08\n",
    "\n",
    "修改为delayed数组，在最后进行计时并且输出；相比此前load的办法的20mins提升到现在的5mins（输出一层850hPa数据），但是这样做的内存开销较大.44G的多层数据写出的开销也只有11mins左右"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据读取、筛选部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_wind = {}\n",
    "ds_qv   = {}\n",
    "\n",
    "# diag数据包含9-1，需要去掉尾部\n",
    "dir_in = \"/raid52/yycheng/MPAS/VR_postprocess/VR_merge_large/ke_daily_vi/\"\n",
    "ds_wind['vr'] = xr.open_mfdataset(dir_in + \"????_VR_ke_daily_vi.nc\", parallel=True)\n",
    "ds_wind['vr'] = ds_wind['vr'].sel(Time = ds_wind['vr'].Time.dt.month.isin([4,5,6,7,8]))\n",
    "dir_in = \"/raid52/yycheng/MPAS/VR_postprocess/VR_merge_large/hum_theta_daily_vi/\"\n",
    "ds_qv['vr'] = xr.open_mfdataset(dir_in + \"????_VR_hum_theta_daily_vi.nc\", parallel=True)\n",
    "ds_qv['vr'] = ds_qv['vr'].sel(Time = ds_qv['vr'].Time.dt.month.isin([4,5,6,7,8]))\n",
    "\n",
    "dir_in = \"/raid52/yycheng/MPAS/RCM_postprocess/RCM_merge_large/ke_daily_vi/\"\n",
    "ds_wind['rcm'] = xr.open_mfdataset(dir_in + \"????_RCM_ke_daily_vi.nc\", parallel=True)\n",
    "ds_wind['rcm'] = ds_wind['rcm'].sel(Time = ds_wind['rcm'].Time.dt.month.isin([4,5,6,7,8]))\n",
    "dir_in = \"/raid52/yycheng/MPAS/RCM_postprocess/RCM_merge_large/hum_theta_daily_vi/\"\n",
    "ds_qv['rcm'] = xr.open_mfdataset(dir_in + \"????_RCM_hum_theta_daily_vi.nc\", parallel=True)\n",
    "ds_qv['rcm'] = ds_qv['rcm'].sel(Time = ds_qv['rcm'].Time.dt.month.isin([4,5,6,7,8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- select data range -----\n",
    "lat_sel     = (ds_qv['vr'].latitude >= 5) & (ds_qv['vr'].latitude <= 60)\n",
    "lon_sel     = (ds_qv['vr'].longitude >= 70) & (ds_qv['vr'].longitude <= 140)\n",
    "plevels_sel = (ds_qv['vr'].plevels == 850) #(ds_qv['vr'].plevels >= 200) & (ds_qv['vr'].plevels <= 925)\n",
    "\n",
    "# plevels_sel = (ds_qv['vr'].plevels == 100)\n",
    "time_year    = (ds_qv['vr'].Time.dt.year >= 1998) # 时次相对较长，一开始使用1998年一年进行尝试\n",
    "time_sel_am     = ds_qv['vr'].Time.dt.month.isin([4,5])\n",
    "time_sel_jja    = ds_qv['vr'].Time.dt.month.isin([6,7,8])\n",
    "\n",
    "sel_dict = {}\n",
    "sel_dict['alltime'] = {'longitude':lon_sel, \"latitude\":lat_sel, \"plevels\":plevels_sel, \"Time\":(time_year)}\n",
    "# sel_dict['am']    = {'longitude':lon_sel, \"latitude\":lat_sel, \"plevels\":plevels_sel, \"Time\":(time_sel_am & time_year)}\n",
    "# sel_dict['jja']   = {'longitude':lon_sel, \"latitude\":lat_sel, \"plevels\":plevels_sel, \"Time\":(time_sel_jja & time_year)}\n",
    "# sel_dict['jja']   = {'longitude':lon_sel, \"latitude\":lat_sel, \"plevels\":plevels_sel, \"Time\":(time_sel_jja & time_year)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读写测试部分\n",
    "\n",
    "写出单个文件所需要的时间\n",
    "\n",
    "- test 1 Time chunks到3060\n",
    "\n",
    "CPU times: user 3min 54s, sys: 25min 4s, total: 28min 59s\n",
    "\n",
    "Wall time: 21min 2s\n",
    "\n",
    "\n",
    "- test 2 使用自定义的chunks\n",
    "\n",
    "CPU times: user 3min 41s, sys: 17min 42s, total: 21min 23s\n",
    "\n",
    "Wall time: 16min 13s\n",
    "\n",
    "- test 3 defalut的chunks，然后不进行load，直接进行写出，只是to_netcdf(compute = False)，在之后的delay写出\n",
    "\n",
    "CPU times: user 1min 48s, sys: 4min 22s, total: 6min 10s\n",
    "\n",
    "Wall time: 5min 17s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.5 ms, sys: 998 µs, total: 14.5 ms\n",
      "Wall time: 12.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# ----- 选取变量 -----\n",
    "mod_list    = ['vr', 'rcm']\n",
    "season_list = ['am', 'jja']\n",
    "\n",
    "u_sel = {}\n",
    "v_sel = {}\n",
    "qv_sel = {}\n",
    "\n",
    "for imod in mod_list:\n",
    "\n",
    "    u_sel[imod]  = ds_wind[imod]['uReconstructZonal'].isel(sel_dict['alltime'])\n",
    "#     v_sel[imod]  = ds_wind[imod]['uReconstructMeridional'].isel(sel_dict['alltime'])\n",
    "#     qv_sel[imod] = ds_qv[imod]['qv'].isel(sel_dict['alltime'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建临时输出\n",
    "输出前先进行load，测试load的时间，输出变量不大，相对速度更快"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  8min 42.5s\n",
      "CPU times: user 2min 8s, sys: 8min 23s, total: 10min 31s\n",
      "Wall time: 8min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from dask.diagnostics import ProgressBar\n",
    "dir_out = \"/raid52/yycheng/MPAS/REFERENCE/TEMP_DATA_large/dyn/wind_shum_850hPa/writing_test/\"\n",
    "delayed_obj = u_sel['vr'].to_netcdf(dir_out + \"writting_test1.nc\", compute = False)\n",
    "\n",
    "with ProgressBar():\n",
    "    results = delayed_obj.compute()\n",
    "    \n",
    "    \n",
    "# var_squeues = [u_sel, v_sel, qv_sel]\n",
    "# var_squeues = [qv_sel]\n",
    "\n",
    "# var_squeues_path = {}\n",
    "\n",
    "# for single_var in var_squeues:\n",
    "#     for imod in ['vr']:\n",
    "#         print(\"deal with: \" + imod)\n",
    "# #         single_var[imod].chunk((3060/10,220,280,1)).to_netcdf(dir_out + 'uwnd/'  + imod + \"_uwind.nc\")\n",
    "# #         v_sel[imod].chunk((3060/10,220,280,1)).to_netcdf(dir_out + 'vwnd/'  + imod + \"_vwind.nc\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5d125e8d1f62ef65bf14791ddcc54379be6b4b51969987cfa8a226a16aec3b4e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('proplot0528': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
