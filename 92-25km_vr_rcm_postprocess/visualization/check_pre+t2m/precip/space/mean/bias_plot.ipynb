{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import proplot as pplt\n",
    "from scipy.fftpack import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2021.08.08\n",
    "\n",
    "尝试使用proplot绘制平均图，分为AM和JJA时间段分别绘制平均态\n",
    "\n",
    "使用pre_process/merge_cmorph_cn051.ipynb 下合并掉cmorph以及cmorph的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_in            = \"/raid52/yycheng/MPAS/REFERENCE/TEMP_DATA_large/pre/ordata/\"\n",
    "filename_vr       = \"vr_pre_98-17.nc\"\n",
    "filename_rcm      = \"rcm_pre_98-17.nc\"\n",
    "filename_obsmerge = \"obsmerge_pre_98-17.nc\"\n",
    "# filename_cn051    = \"large_CN05.1_Pre_1961_2018_daily_025x025.nc\"\n",
    "filename_cn051    = \"sel_CN05.1_Pre_1961_2018_daily_025x025.nc\"\n",
    "filename_cmorph   = 'large_CMORPH_98-17.nc'\n",
    "\n",
    "ds_or = {}\n",
    "var = {}\n",
    "var['vr']     = xr.open_dataset(dir_in + filename_vr)['precip_MPAS']\n",
    "var['rcm']    = xr.open_dataset(dir_in + filename_rcm  )['precip_MPAS']\n",
    "var['obsmerge']    = xr.open_dataset(dir_in + filename_obsmerge)['premerge']\n",
    "var['cmorph']    = xr.open_dataset(dir_in + filename_cmorph)['cmorph'][:,0,:,:]\n",
    "var['cn05.1']    = xr.open_dataset(dir_in + filename_cn051)['pre']\n",
    "\n",
    "var['obsmerge'] = var['obsmerge'].reset_coords(names = 'lev', drop = True) # 去除掉obs中多余的lev coords\n",
    "var['cmorph'] = var['cmorph'].reset_coords(names = 'lev', drop = True) # 去除掉obs中多余的lev coords\n",
    "\n",
    "# CN05.1 的坐标范围相比其他数据较小，将CN05.1的范围扩展到较大的domain上，并且用NAN填充\n",
    "empty_da = xr.DataArray(np.empty(shape = var['cmorph'].shape), coords = var['cmorph'].coords)\n",
    "empty_da[:,:,:] = np.nan\n",
    "lat_smallcn051 = var['cn05.1'].lat\n",
    "lon_smallcn051 = var['cn05.1'].lon\n",
    "empty_da.loc[{\"lat\" : lat_smallcn051, \"lon\" : lon_smallcn051}] = var['cn05.1'].values\n",
    "var['cn05.1'] = empty_da\n",
    "\n",
    "# change coords\n",
    "\n",
    "var_list = ['vr', 'rcm', 'obsmerge', 'cmorph', 'cn05.1']\n",
    "for i in var_list:\n",
    "    rename_dict = dict(zip(var[i].coords.keys(), var['obsmerge'].coords.keys()))\n",
    "#     # show converting coords\n",
    "    for rename_i in rename_dict:\n",
    "        print(rename_i + \" -----converting to----- \" + rename_dict[rename_i])\n",
    "\n",
    "    var[i] = var[i].rename(rename_dict)\n",
    "    var[i]._coords = var['obsmerge']._coords\n",
    "    var[i] = var[i].rename(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_selmonth = {}\n",
    "var_selmonth['mjja'] = {}\n",
    "time_idx_mjja = var['obsmerge'].time.dt.month.isin([5,6,7,8])\n",
    "\n",
    "for mod_name in ['cn05.1','cmorph','obsmerge', 'vr', 'rcm']:\n",
    "    var_selmonth['mjja'][mod_name] = var[mod_name].isel(time = time_idx_mjja).mean(dim = 'time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算指标"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算制图表格 2022.02.17\n",
    "\n",
    "需要分别用 CMORPH CN05.1 CMORPH_OUTSIDE 作为观测计算表格\n",
    "\n",
    "先去除掉陆地上的CMORPH，构造 cmorph_outside 观测数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skill_metrics as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 制作海洋上的CMORPH_OUTSIDE\n",
    "cmorph_outside_mask = np.isnan(var_selmonth['mjja']['cn05.1'])\n",
    "var_selmonth['mjja']['cmorph_outside'] = var_selmonth['mjja']['cmorph'].where(cmorph_outside_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_dict():\n",
    "    from collections import defaultdict\n",
    "    return defaultdict(nested_dict)\n",
    "# 进行mask，并且整理成1D数组，得到1D-pattern，用于后续的计算\n",
    "# 计算指数的平均值\n",
    "\n",
    "ind = np.array([0])\n",
    "pd_templist = []\n",
    "for observation_set in ['cn05.1','cmorph','cmorph_outside']:\n",
    "# for observation_set in ['obsmerge']:\n",
    "\n",
    "    var_1d = {}\n",
    "    iseason = 'mjja'\n",
    "    for mod_name in [observation_set, 'vr', 'rcm']:\n",
    "            # 获取1D的平均态 并以RCM为基础进行NAN的MASK\n",
    "            index_not_nan = ( ~np.isnan(var_selmonth[iseason]['rcm'])) &\\\n",
    "                (~np.isnan(var_selmonth[iseason][observation_set])) &\\\n",
    "                (~np.isnan(var_selmonth[iseason]['vr']) )\n",
    "            var_1d_temp = xr.where(index_not_nan, var_selmonth[iseason][mod_name], np.nan).values.ravel()\n",
    "            var_1d[mod_name] = var_1d_temp[~np.isnan(var_1d_temp)]\n",
    "\n",
    "    for mod_name in [observation_set, 'vr', 'rcm']:\n",
    "        temp_mean  = var_1d[mod_name].mean()\n",
    "        temp_bias  = sm.bias(var_1d[mod_name], var_1d[observation_set])\n",
    "        temp_rmsd  = sm.rmsd(var_1d[mod_name], var_1d[observation_set])\n",
    "        temp_ccoef = np.corrcoef(var_1d[mod_name], var_1d[observation_set])[1,0]\n",
    "\n",
    "        pd_templist.append( pd.DataFrame(data = [['precip',observation_set + \"-\" + mod_name, temp_mean, temp_bias, temp_ccoef, temp_rmsd]], \\\n",
    "        columns = ['variable','obs-model','mean', 'bias','ccoef','rmsd'], index=  ind) )\n",
    "        ind = ind + 1\n",
    "\n",
    "# 合并表格并写出\n",
    "table_pdconcat = pd.concat(pd_templist)\n",
    "table_pdconcat.to_csv(\"./output_table/dailypre_SpatialTaylor_2022.02.17.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算制图表格\n",
    "\n",
    "弃用；不需要rmsd crmsd；并且需要针对两个观测数据集特别计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_dict():\n",
    "    from collections import defaultdict\n",
    "    return defaultdict(nested_dict)\n",
    "# 进行mask，并且整理成1D数组，得到1D-pattern，用于后续的计算\n",
    "# 计算指数的平均值\n",
    "var_1d = nested_dict()\n",
    "for iseason in ['mjja']:\n",
    "    for mod_name in ['cn05.1','cmorph','obsmerge', 'vr', 'rcm']:\n",
    "            # 获取1D的平均态 并以RCM为基础进行NAN的MASK\n",
    "            rcm_not_nan = ( ~np.isnan(var_selmonth['mjja']['rcm'])) &\\\n",
    "                 (~np.isnan(var_selmonth['mjja']['obsmerge'])) &\\\n",
    "                 (~np.isnan(var_selmonth['mjja']['vr']) )\n",
    "            var_1d_temp = xr.where(rcm_not_nan, var_selmonth[iseason][mod_name], np.nan).values.ravel()\n",
    "            var_1d[iseason][mod_name] = var_1d_temp[~np.isnan(var_1d_temp)]\n",
    "            # shape check\n",
    "            # print(var_1d[iseason][var_name][mod_name].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skill_metrics as sm\n",
    "# 计算泰勒图诸要素 到字典taylor_ts中\n",
    "# 进行mask，并且整理成1D数组，得到1D-pattern，用于后续的计算\n",
    "# 计算指数的平均值\n",
    "taylor_space = nested_dict()\n",
    "for iseason in ['mjja']:\n",
    "    for mod_name in ['obsmerge', 'vr', 'rcm']:\n",
    "        temp_obs = var_1d[iseason]['obsmerge']\n",
    "        temp_mod = var_1d[iseason][mod_name]\n",
    "        # taylor count\n",
    "        taylor_space[iseason][mod_name] = sm.taylor_statistics(temp_mod, temp_obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 合并表格并写出csv文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_templist = []\n",
    "ind = np.array([0]) # index的整数\n",
    "for iseason in ['mjja']:\n",
    "    for mod_name in ['obsmerge', 'vr', 'rcm']:\n",
    "        temp_ccoef = taylor_space[iseason][mod_name]['ccoef'][1]\n",
    "        temp_crmsd = taylor_space[iseason][mod_name]['crmsd'][1]\n",
    "        temp_sdev  = taylor_space[iseason][mod_name]['sdev'][1]\n",
    "        temp_mean  = var_1d[iseason][mod_name].mean()\n",
    "        # temp_bias  = var_1d[iseason][mod_name].mean() - var_1d[iseason]['obsmerge'].mean()\n",
    "        temp_bias  = sm.bias(var_1d[iseason][mod_name], var_1d[iseason]['obsmerge'])\n",
    "        temp_rmsd  = sm.rmsd(var_1d[iseason][mod_name], var_1d[iseason]['obsmerge'])\n",
    "    \n",
    "        pd_templist.append( pd.DataFrame(data = [['precip',mod_name, temp_mean, temp_bias, temp_ccoef, temp_crmsd, temp_rmsd, temp_sdev]], \\\n",
    "            columns = ['variable','model','mean', 'bias','ccoef','crmsd','rmsd','sdev'], index=  ind) )\n",
    "        ind = ind + 1\n",
    "\n",
    "# 合并表格并写出\n",
    "table_pdconcat = pd.concat(pd_templist)\n",
    "table_pdconcat.to_csv(\"./output_table/dailypre_SpatialTaylor_2022.02.14.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_pdconcat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 绘图部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 国内政区图的绘制\n",
    "# Load the border data, CN-border-La.dat is download from\n",
    "# https://gmt-china.org/data/CN-border-La.dat\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.io.shapereader as shpreader\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "cn_border_file = \"/m2data2/yycheng/data_stage/CN-border/CN-border_line/CN-border-La.dat\"\n",
    "with open(cn_border_file) as src:\n",
    "    context = src.read()\n",
    "    blocks = [cnt for cnt in context.split('>') if len(cnt) > 0]\n",
    "    borders = [np.fromstring(block, dtype=float, sep=' ') for block in blocks]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 画图renew\n",
    "#### 2021.08.08\n",
    "cn_border_file + shapefile ，但是存在重叠，尝试消除掉China边界，但是其他邻国边界无法处理；\n",
    "#### 2021.08.09\n",
    "不使用cn_border_file ，使用shapefile + coast_line（proplot自带） 的办法\n",
    "shapefile有一些重叠，不绘制行政区\n",
    "shapefile重新进行绘制，考虑来自 domain_info 中测试的多个shape file中挑选出地资所（改变了prj方式，具体查看prj后缀文件）进行使用\n",
    "#### 2021.08.30\n",
    "添加误差图，并且shapefile中的river挑选长江、黄河绘制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def border_plot(axs):\n",
    "    \"\"\"\n",
    "    进行行政区划的绘制，通过shapefilereader绘制存档的shp文件，需要传入axs，并逐个绘制\n",
    "    比较消耗时间，调整完毕后最后添加边界的绘制\n",
    "    \"\"\"\n",
    "    ##---- 直接绘图，从边界文件添加\n",
    "    # for ax_ind in axs:\n",
    "    # for line in borders:\n",
    "    #     axs.plot(line[0::100], line[1::100], lw = 0.5, color='gray',transform=ccrs.Geodetic())\n",
    "    #     axs.plot(line[0::10], line[1::10], lw = 0.4, color='black',transform=ccrs.Geodetic())\n",
    "    ##---- 使用shp文件添加\n",
    "        # shapefile数据下载的位置：\n",
    "    # http://gaohr.win/site/blogs/2017/2017-04-18-GIS-basic-data-of-China.html\n",
    "    world_border_shapefile = \"/m2data2/yycheng/data_stage/CN-border/World/country.shp\"\n",
    "    river_border_shapefile =  \"/raid52/yycheng/MPAS/REFERENCE/MODEL_CONSTANT/R1/\" + \"hyd1_4l.shp\"\n",
    "    southsea_shapefile     = \"/m2data2/yycheng/data_stage/CN-border/SouthSea/\" + \"southsea_island.shp\"\n",
    "    ninelines_shapefile     = \"/m2data2/yycheng/data_stage/CN-border/SouthSea/\" + \"nine_lines.shp\"\n",
    "    ## 来源： 沛沛的诸省 + 诸岛\n",
    "    bou24p_shapefile     = \"/m2data2/yycheng/data_stage/CN-border/peipeihelp/\" + \"bou2_4p.shp\"\n",
    "    ## 来源： https://www.resdc.cn/data.aspx?DATAID=200\n",
    "    province_shapefile     = \"/m2data2/yycheng/data_stage/CN-border/CN-sheng/\" + \"change_proj_CN-sheng-A.shp\"\n",
    "\n",
    "    for ax in axs:\n",
    "        # world     = shpreader.Reader(world_border_shapefile).geometries()\n",
    "        # river     = shpreader.Reader(river_border_shapefile).geometries()\n",
    "        river     = shpreader.Reader(river_border_shapefile, encoding = \"gbk\")\n",
    "        # bou24p    = shpreader.Reader(bou24p_shapefile).geometries()\n",
    "        ninelines = shpreader.Reader(ninelines_shapefile).geometries()\n",
    "        province  = shpreader.Reader(province_shapefile).geometries()\n",
    "        # ax.add_geometries(river, ccrs.PlateCarree(), facecolor='none', edgecolor='b', linewidth=0.4, zorder=1)\n",
    "        # ax.add_geometries(world, ccrs.PlateCarree(), facecolor='none', edgecolor='k', linewidth=0.4, zorder=1)\n",
    "        # ax.add_geometries(bou24p, ccrs.PlateCarree(), facecolor='none', edgecolor='k', linewidth=0.6, zorder=1) # 沛沛map\n",
    "        ax.add_geometries(province, ccrs.PlateCarree(), facecolor='none', edgecolor='k', linewidth=0.6, zorder=1) # 地资所\n",
    "        ax.add_geometries(ninelines, ccrs.PlateCarree(), facecolor='none', edgecolor='k', linewidth=0.6, zorder=1)\n",
    "        # 绘制部分的shapefile\n",
    "        for region in river.records():\n",
    "            if (region.attributes['NAME'] in ['黄河','长江']):\n",
    "                # print(\"----- draw river! -----\")\n",
    "                # 此处需要使用 [] 让region.geometry可以迭代\n",
    "                ax.add_geometries([region.geometry], ccrs.PlateCarree(), facecolor='none', edgecolor='b', linewidth=0.4, zorder=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import proplot as plot\n",
    "from matplotlib import pyplot as plt\n",
    "import proplot as plot\n",
    "import cmaps\n",
    "# ----- get filter vars coords-----\n",
    "\n",
    "lon = var_selmonth['mjja']['vr'].lon.values\n",
    "lat = var_selmonth['mjja']['vr'].lat.values\n",
    "\n",
    "#----- create plot -----\n",
    "fig, axs = plot.subplots(ncols=3 ,nrows=2, proj=('cyl'))\n",
    "m_contour_list = [] # 用于保存contour设置，后续设置colorbar使用\n",
    "\n",
    "#----- 添加海洋以及行政区划 -----\n",
    "border_plot(axs)\n",
    "\n",
    "#----- colorbar ticks 统一设置 -----\n",
    "# cmap = 'gist_ncar'\n",
    "cmap = cmaps.cmocean_deep\n",
    "# cmap_diff = cmaps.cmp_flux_r\n",
    "cmap_diff = cmaps.ncl_default_r\n",
    "# cmap_diff = cmaps.precip4_diff_19lev\n",
    "\n",
    "mean_ticks = np.concatenate((np.linspace(1,5,5), np.linspace(6,16,6)), axis=0)\n",
    "# mean_ticks = np.arange(0,18,2)\n",
    "# mean_ticks = np.linspace(0,20,21)\n",
    "print(\"----- tick levels is : \" + str(mean_ticks))\n",
    "diff_ticks = np.linspace(-4, 15, 20)\n",
    "# diff_ticks = np.concatenate((np.linspace(-5,0,6), np.linspace(1,10,10), [12,14,16,20]), axis=0)\n",
    "\n",
    "m_mean = axs[0].contourf(lon, lat, var_selmonth['mjja']['cn05.1'].values,\\\n",
    "levels=mean_ticks,cmap=cmap, extend = 'both', norm = 'segmented')\n",
    "\n",
    "m_mean = axs[3].contourf(lon, lat, var_selmonth['mjja']['cmorph'].values,\\\n",
    "levels=mean_ticks,cmap=cmap, extend = 'both', norm = 'segmented')\n",
    "\n",
    "for mod_ind, mod_name in enumerate(['vr','rcm']):\n",
    "    midnorm = plot.DivergingNorm(vcenter = 0, fair = False)\n",
    "    m_diff = axs[mod_ind+1].contourf(lon, lat, var_selmonth['mjja'][mod_name].values - var_selmonth['mjja']['cn05.1'].values,\\\n",
    "    levels=diff_ticks,cmap=cmap_diff, norm = midnorm, extend = 'both')\n",
    "    m_diff = axs[mod_ind+3+1].contourf(lon, lat, var_selmonth['mjja'][mod_name].values - var_selmonth['mjja']['cmorph'].values,\\\n",
    "    levels=diff_ticks,cmap=cmap_diff, norm = midnorm, extend = 'both')\n",
    "\n",
    "\n",
    "#----- add color bar-----\n",
    "# fig.colorbar(m_overlay, loc='b', cmap=cmap, width=0.1)\n",
    "\n",
    "fig.colorbar(m_mean, loc='r', width=0.1,\n",
    "ticklabelsize=5,ticks=mean_ticks, title='precipitation [mm/day]', extend = 'both')\n",
    "fig.colorbar(m_diff, loc='r', width=0.1,\n",
    "ticklabelsize=5,ticks=diff_ticks, title='bias' + '[mm/day]', extend = 'both')\n",
    "\n",
    "\n",
    "# ----- format setting -----\n",
    "axs.format(\n",
    "abc=True,\n",
    "abcloc = 'ul',\n",
    "#----- 地图底图设置 -----\n",
    "# reso = 'x-hi',\n",
    "reso = 'med',\n",
    "# coast = False,\n",
    "coast = True,\n",
    "coastlinewidth = 0.4,\n",
    "borders = False,\n",
    "lakes = False,\n",
    "land  = False,\n",
    "ocean = False,\n",
    "# cartopyautoextent = True, \n",
    "# borderslinewidth=.5,\n",
    "labels = True,\n",
    "longrid  = True,\n",
    "latgrid  = True,\n",
    "#-----GEO axis-----\n",
    "lonlim=(70, 140), latlim=(5, 60),\n",
    "gridlabelsize = 5,\n",
    "gridminor = True,\n",
    "lonlocator = np.arange(70,142,10),\n",
    "latlocator = np.arange(5,70+2,10),\n",
    "lonminorlocator = np.arange(70,140+2,2),\n",
    "latminorlocator = np.arange(5,70+2,2),\n",
    "#-----line label-----\n",
    "# linewidth = 0.5,\n",
    "suptitle=\"precipitation\",\n",
    ")\n",
    "\n",
    "# ----- add axses title and labels setting -----\n",
    "axs.format(titleweight = 'bold')\n",
    "axs[0].format(title = \"CN05.1\")\n",
    "axs[1].format(title = \"VR\")\n",
    "axs[2].format(title = \"RCM\")\n",
    "\n",
    "axs[3].format(title = \"CMORPH\")\n",
    "axs[4].format(title = \"VR\")\n",
    "axs[5].format(title = \"RCM\")\n",
    "\n",
    "#----- save figure -----\n",
    "fig.patch.set_facecolor('white')\n",
    "plt.savefig('./output_pic/pre_meanstates.2022.02.13.png', dpi=600, facecolor= \"white\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "da0469cb1653dac5810650c6f9c12d7c46a389e85e448c305f1477fdb1af5288"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('proplot0528': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
