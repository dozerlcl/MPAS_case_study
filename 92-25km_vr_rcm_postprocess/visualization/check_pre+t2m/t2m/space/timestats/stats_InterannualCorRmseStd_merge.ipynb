{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import proplot as pplt\n",
    "from scipy.fftpack import * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2021.08.08\n",
    "\n",
    "尝试使用proplot绘制平均图\n",
    "\n",
    "使用pre_process/merge_cmorph_cn051.ipynb 下合并掉cmorph以及cmorph的数据·"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据读入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_in = \"/raid52/yycheng/MPAS/REFERENCE/TEMP_DATA/mask_t2m/mask_res/\"\n",
    "filename_obs  = \"mask_sel_CN05.1_Tm_1961_2018_daily_025x025.nc\"\n",
    "filename_vr     = \"mask_mean_t2m_98-17_VR.nc\"\n",
    "filename_rcm    = \"mask_mean_t2m_98-17_RCM.nc\"\n",
    "\n",
    "ds_or = {}\n",
    "ds_or['obs'] = xr.open_dataset(dir_in + filename_obs)\n",
    "ds_or['vr']     = xr.open_dataset(dir_in + filename_vr)\n",
    "ds_or['rcm']    = xr.open_dataset(dir_in + filename_rcm  )\n",
    "# 提取变量\n",
    "var = {}\n",
    "var['obs'] = ds_or['obs']['tm']#[:,  :, :]\n",
    "var['vr'] = ds_or['vr']['t2m'] - 273.15\n",
    "var['rcm'] = ds_or['rcm']['t2m'] - 273.15\n",
    "\n",
    "# var['obs'] = var['obs'].reset_coords(names = 'lev', drop = True) # 去除掉obs中多余的lev coords\n",
    "\n",
    "# change coords\n",
    "var_list = ['obs', 'vr', 'rcm']\n",
    "for i in var_list:\n",
    "    rename_dict = dict(zip(var[i].coords.keys(), var['obs'].coords.keys()))\n",
    "#     # show converting coords\n",
    "    for rename_i in rename_dict:\n",
    "        print(rename_i + \" -----converting to----- \" + rename_dict[rename_i])\n",
    "\n",
    "    var[i] = var[i].rename(rename_dict)\n",
    "    var[i]._coords = var['obs']._coords\n",
    "    var[i] = var[i].rename(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_selmonth = {}\n",
    "var_selmonth['am'] = {}\n",
    "var_selmonth['jja'] = {}\n",
    "\n",
    "time_idx_am = var['obs'].time.dt.month.isin([4,5])\n",
    "time_idx_jja = var['obs'].time.dt.month.isin([6,7,8])\n",
    "\n",
    "for mod_name in ['obs', 'vr', 'rcm']:\n",
    "    var_selmonth['am'][mod_name]  = var[mod_name].isel(time = time_idx_am)\n",
    "    var_selmonth['jja'][mod_name] = var[mod_name].isel(time = time_idx_jja)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算年际相关系数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取年际时间序列 var_interannual{} dict\n",
    "var_interannual = {}\n",
    "time_for_groupby = {}\n",
    "time_for_groupby['am'] = var_selmonth['am']['vr'].time.dt.year\n",
    "time_for_groupby['jja'] = var_selmonth['jja']['vr'].time.dt.year\n",
    "\n",
    "for iseason in ['am', 'jja']:\n",
    "    var_interannual[iseason] = {}\n",
    "    for mod_name in ['obs', 'vr', 'rcm']:\n",
    "        var_interannual[iseason][mod_name] = var_selmonth[iseason][mod_name].groupby(time_for_groupby[iseason]).mean(dim = 'time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scipy_count_corr_2d(a,b):\n",
    "    '计算两个3D序列在时间维上的相关性，使用scipy逐个格点的计算，获取pvalues,输入数组a,b 按照 time x lat x lon的方式进行排列'\n",
    "    '如果第一个时次出现了np.nan ,那么就对这个格点赋值为nan'\n",
    "    import numpy as np\n",
    "    from scipy import stats\n",
    "\n",
    "    dim1 = a.shape[1]\n",
    "    dim2 = a.shape[2]\n",
    "    pvalues = np.empty(shape = a.shape[1:])\n",
    "    corrvalues = np.empty(shape = a.shape[1:])\n",
    "    # np.corrcoef?\n",
    "    for ilat in range(0, dim1):\n",
    "        for ilon in range(0, dim2):\n",
    "            if ( (np.isnan(a[0,ilat,ilon])) | (np.isnan(b[0,ilat,ilon])) ):\n",
    "                corrvalues[ilat, ilon], pvalues[ilat, ilon] = np.nan, np.nan\n",
    "                continue    \n",
    "            corrvalues[ilat, ilon], pvalues[ilat, ilon] \\\n",
    "                = stats.pearsonr(a[:,ilat,ilon], b[:,ilat,ilon])\n",
    "    return [corrvalues, pvalues]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_interannual = {}\n",
    "\n",
    "for iseason in ['am', 'jja']:\n",
    "    corr_interannual[iseason] = {}\n",
    "    for mod_name in ['vr', 'rcm']:\n",
    "        corr_interannual[iseason][mod_name]  = {}\n",
    "        corr_interannual[iseason][mod_name]['corr']    = \\\n",
    "            xr.corr(var_interannual[iseason]['obs'], var_interannual[iseason][mod_name], dim= 'year')\n",
    "        corr_scipy, pvalues_scipy = \\\n",
    "            scipy_count_corr_2d(var_interannual[iseason]['obs'].values, var_interannual[iseason][mod_name].values)\n",
    "        corr_interannual[iseason][mod_name]['pvalues'] = xr.DataArray(pvalues_scipy, coords = \\\n",
    "            corr_interannual[iseason][mod_name]['corr'].coords, name = 'pvalues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算年际方差\n",
    "\n",
    "2021.12.27 进行变率的分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance_interannual = {}\n",
    "std_interannual = {}\n",
    "for iseason in ['am', 'jja']:\n",
    "    variance_interannual[iseason] = {}\n",
    "    std_interannual[iseason] = {}\n",
    "    for mod_name in ['obs', 'vr','rcm']:\n",
    "        variance_temp = var_interannual[iseason][mod_name].var(dim = \"year\")\n",
    "        std_temp = var_interannual[iseason][mod_name].std(dim = \"year\")\n",
    "        coords2d = {\"lon\":var_interannual[iseason][mod_name].lon, \"lat\":var_interannual[iseason][mod_name].lat}\n",
    "        variance_interannual[iseason][mod_name] = xr.DataArray(variance_temp, coords = coords2d, name = 'variance')\n",
    "        std_interannual[iseason][mod_name] = xr.DataArray(std_temp, coords = coords2d, name = 'variance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算年纪均方根误差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_interannual = {}\n",
    "\n",
    "for iseason in ['am', 'jja']:\n",
    "    rmse_interannual[iseason] = {}\n",
    "    for mod_name in ['vr','rcm']:\n",
    "        nyears = var_interannual[iseason][mod_name].year.shape[0]\n",
    "        rmse_temp = np.sqrt( ( (var_interannual[iseason][mod_name].values - var_interannual[iseason]['obs'].values)**2).sum(axis = 0) / nyears)\n",
    "        rmse_interannual[iseason][mod_name] = xr.DataArray(rmse_temp, coords = \\\n",
    "            corr_interannual[iseason][mod_name]['corr'].coords, name = 'rmse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 绘图部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 调整cmap，去掉gist_ncar 中深蓝色的部分\n",
    "# https://stackoverflow.com/questions/18926031/how-to-extract-a-subset-of-a-colormap-as-a-new-colormap-in-matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import numpy as np\n",
    "import cmaps\n",
    "def truncate_colormap(cmap, minval=0.0, maxval=1.0, n=100):\n",
    "    new_cmap = colors.LinearSegmentedColormap.from_list(\n",
    "        'trunc({n},{a:.2f},{b:.2f})'.format(n=cmap.name, a=minval, b=maxval),\n",
    "        cmap(np.linspace(minval, maxval, n)))\n",
    "    return new_cmap\n",
    "\n",
    "arr = np.linspace(0, 50, 100).reshape((10, 10))\n",
    "fig, ax = plt.subplots(ncols=2)\n",
    "\n",
    "# cmap_corr     = plt.get_cmap('bwr')\n",
    "cmap_corr     = cmaps.ncl_default\n",
    "cmap_rmse     = plt.get_cmap('gist_ncar')\n",
    "new_cmap_corr = truncate_colormap(cmap_corr, 0., 1.)\n",
    "new_cmap_rmse = truncate_colormap(cmap_rmse, 0.4, 1.)\n",
    "ax[0].imshow(arr, interpolation='nearest', cmap=cmap_rmse)\n",
    "ax[1].imshow(arr, interpolation='nearest', cmap=new_cmap_rmse)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 国内政区图的绘制\n",
    "# Load the border data, CN-border-La.dat is download from\n",
    "# https://gmt-china.org/data/CN-border-La.dat\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.io.shapereader as shpreader\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "cn_border_file = \"/m2data2/yycheng/data_stage/CN-border/CN-border_line/CN-border-La.dat\"\n",
    "with open(cn_border_file) as src:\n",
    "    context = src.read()\n",
    "    blocks = [cnt for cnt in context.split('>') if len(cnt) > 0]\n",
    "    borders = [np.fromstring(block, dtype=float, sep=' ') for block in blocks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_borders(axs):\n",
    "    # for ax_ind in axs:\n",
    "    # for line in borders:\n",
    "    # axs.plot(line[0::100], line[1::100], lw = 0.5, color='gray',transform=ccrs.Geodetic())\n",
    "    # axs.plot(line[0::10], line[1::10], lw = 0.4, color='black',transform=ccrs.Geodetic())\n",
    "    ##---- 使用shp文件添加\n",
    "    ## shapefile数据下载的位置：\n",
    "    ## http://gaohr.win/site/blogs/2017/2017-04-18-GIS-basic-data-of-China.html\n",
    "    # world_border_shapefile = \"/m2data2/yycheng/data_stage/CN-border/World/country.shp\"\n",
    "    river_border_shapefile =  \"/raid52/yycheng/MPAS/REFERENCE/MODEL_CONSTANT/R1/\" + \"hyd1_4l.shp\"\n",
    "    southsea_shapefile     = \"/m2data2/yycheng/data_stage/CN-border/SouthSea/\" + \"southsea_island.shp\"\n",
    "    ninelines_shapefile     = \"/m2data2/yycheng/data_stage/CN-border/SouthSea/\" + \"nine_lines.shp\"\n",
    "    ## 来源： 沛沛的诸省 + 诸岛\n",
    "    bou24p_shapefile     = \"/m2data2/yycheng/data_stage/CN-border/peipeihelp/\" + \"bou2_4p.shp\"\n",
    "    ## 来源： https://www.resdc.cn/data.aspx?DATAID=200\n",
    "    province_shapefile     = \"/m2data2/yycheng/data_stage/CN-border/CN-sheng/\" + \"change_proj_CN-sheng-A.shp\"\n",
    "\n",
    "    for ax in axs:\n",
    "        # world     = shpreader.Reader(world_border_shapefile).geometries()\n",
    "        river     = shpreader.Reader(river_border_shapefile).geometries()\n",
    "        # bou24p    = shpreader.Reader(bou24p_shapefile).geometries()\n",
    "        ninelines = shpreader.Reader(ninelines_shapefile).geometries()\n",
    "        province  = shpreader.Reader(province_shapefile).geometries()\n",
    "        ax.add_geometries(river, ccrs.PlateCarree(), facecolor='none', edgecolor='b', linewidth=0.4, zorder=1)\n",
    "        # ax.add_geometries(world, ccrs.PlateCarree(), facecolor='none', edgecolor='k', linewidth=0.4, zorder=1)\n",
    "        # ax.add_geometries(bou24p, ccrs.PlateCarree(), facecolor='none', edgecolor='k', linewidth=0.6, zorder=1) # 沛沛map\n",
    "        ax.add_geometries(province, ccrs.PlateCarree(), facecolor='none', edgecolor='k', linewidth=0.6, zorder=1) # 地资所\n",
    "        ax.add_geometries(ninelines, ccrs.PlateCarree(), facecolor='none', edgecolor='k', linewidth=0.6, zorder=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 画图renew\n",
    "#### 2021.08.08\n",
    "cn_border_file + shapefile ，但是存在重叠，尝试消除掉China边界，但是其他邻国边界无法处理；\n",
    "#### 2021.08.09\n",
    "\n",
    "不使用cn_border_file ，使用shapefile + coast_line（proplot自带） 的办法\n",
    "\n",
    "shapefile有一些重叠，不绘制行政区\n",
    "\n",
    "shapefile重新进行绘制，考虑来自 domain_info 中测试的多个shape file中挑选出地资所（改变了prj方式之后就可以正常绘制，具体查看prj后缀文件）进行使用\n",
    "\n",
    "如果都使用环资所的全球、全国数据，那么是不会出现问题的\n",
    "\n",
    "#### 2021.08.13\n",
    "绘制相关性，使用hatch打点比较困难，这里直接考虑使用scatter打点，并且对过于密集的格点手动降低了密度 [::4] 散点大小约为1°\n",
    "\n",
    "#### 2021.12.27\n",
    "重新在此处添加年际变率（variance）的空间patterns的绘制，放弃之前的ncl脚本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 绘制TCC RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import proplot as plot\n",
    "from matplotlib import pyplot as plt\n",
    "import proplot as plot\n",
    "# ----- get filter vars coords-----\n",
    "\n",
    "lon = corr_interannual['am']['vr']['corr'].lon.values\n",
    "lat = corr_interannual['am']['vr']['corr'].lat.values\n",
    "\n",
    "#----- create plot -----\n",
    "subplot_shape = [ [1,1,2,2,3,3,4,4],\\\n",
    "    [5,5,6,6,7,7,8,8],\\\n",
    "    [0,9,9,10,10,11,11,0],\\\n",
    "    [0,12,12,13,13,14,14,0]]\n",
    "fig, axs = plot.subplots(subplot_shape, proj=('cyl'),space = 2.5)\n",
    "m_contour_list = [] # 用于保存contour设置，后续设置colorbar使用\n",
    "\n",
    "#----- 添加海洋以及行政区划 -----\n",
    "draw_borders(axs)\n",
    "\n",
    "#----- colorbar ticks 统一设置 -----\n",
    "# cmap = 'gist_ncar'\n",
    "# cmap = new_cmap\n",
    "# cmap = cmap_data\n",
    "corr_ticks = np.linspace(-1,1, 21)\n",
    "# rmse_ticks = np.linspace(0, 7, 15)\n",
    "rmse_ticks = np.concatenate((np.linspace(0,7,29),[8,9,10]), axis=0)\n",
    "cmap_std = cmaps.BkBlAqGrYeOrReViWh200\n",
    "# cmap_std_diff = cmaps.NCV_blue_red\n",
    "cmap_std_diff = cmaps.cmp_flux\n",
    "std_ticks = np.linspace(0.2,1.2,21)\n",
    "std_ticks_diff = np.concatenate( (np.linspace(-0.5,-0.1,5), np.linspace(0,3.,16)), axis = 0) \n",
    "\n",
    "midnorm = pplt.DivergingNorm(vcenter = 0, fair = False)\n",
    "\n",
    "\n",
    "# plot contourf and titile axs\n",
    "\n",
    "for season_ind, season_name in enumerate(['am','jja']):\n",
    "    for mod_ind, mod_name in enumerate(['vr','rcm']):\n",
    "        plot_ind = season_ind*4 + mod_ind\n",
    "        # corr\n",
    "        m_corr  = axs[plot_ind].contourf(lon, lat, corr_interannual[season_name][mod_name]['corr'].values,\\\n",
    "        levels=corr_ticks,cmap=new_cmap_corr, extend = 'both')\n",
    "        # 绘制散点\n",
    "        # 需要将原本密集的格点散点减少 (::4) 然后找到减少后的经纬度lon[::4] 进行散点的绘制\n",
    "        scatter_test = np.argwhere((corr_interannual[season_name][mod_name]['pvalues'][::4,::4]<0.05).values)\n",
    "        axs[plot_ind].scatter(lon[::4][scatter_test[:,1]],lat[::4][scatter_test[:,0]], s=0.15, color = 'k', marker='o')\n",
    "        axs[plot_ind].format(ltitle = season_name.upper(), title = mod_name.upper(), rtitle = 'CORR')\n",
    "        # rmse\n",
    "        m_rmse  = axs[plot_ind + 2].contourf(lon, lat, rmse_interannual[season_name][mod_name].values,\\\n",
    "        levels=rmse_ticks,cmap=new_cmap_rmse, extend = 'both')\n",
    "        axs[plot_ind + 2].format(ltitle = season_name.upper(), title = mod_name.upper(), rtitle = 'RMSE')\n",
    "\n",
    "# std\n",
    "for season_ind, season_name in enumerate(['am','jja']):\n",
    "    for mod_ind, mod_name in enumerate(['obs','vr','rcm']):\n",
    "        plot_ind = 8 + season_ind*3 + mod_ind\n",
    "        # std\n",
    "        if (mod_name == 'obs'):\n",
    "            m_std  = axs[plot_ind].contourf(lon, lat, std_interannual[season_name][mod_name].values,\\\n",
    "            levels=std_ticks,cmap=cmap_std, norm = 'segmented', extend = 'both')\n",
    "        else:\n",
    "            m_std_diff  = axs[plot_ind].contourf(lon, lat, std_interannual[season_name][mod_name].values - std_interannual[season_name]['obs'].values,\\\n",
    "            levels=std_ticks_diff,cmap=cmap_std_diff, norm = midnorm, discrete = True, extend = 'both')\n",
    "\n",
    "        axs[plot_ind].format(ltitle = season_name.upper(), title = mod_name.upper(), rtitle = 'STD')\n",
    "\n",
    "\n",
    "#----- add color bar-----\n",
    "\n",
    "fig.colorbar(m_corr, loc='r', width=0.1, rows = (1,2),\n",
    "ticklabelsize=5,ticks=corr_ticks, title='corrleation', extend = 'both')\n",
    "\n",
    "fig.colorbar(m_rmse, loc='r', width=0.1, rows = (1,2),\n",
    "ticklabelsize=5,ticks=rmse_ticks[::2], title='RMSE ' + r\"$[^\\circ C]$\", extend = 'both')\n",
    "\n",
    "fig.colorbar(m_std, loc='r', width=0.1,rows = (3,4),norm = 'segmented',\n",
    "ticklabelsize=5,ticks=std_ticks, title='standard deviation ' + r\"$[^\\circ C]$\", extend = 'both')\n",
    "\n",
    "fig.colorbar(m_std_diff, loc='r', width=0.1,rows = (3,4),\n",
    "ticklabelsize=5,ticks=std_ticks_diff, title=\"std differences \" + r\"$[^\\circ C]$\", \\\n",
    "norm = midnorm, extend = 'both')\n",
    "\n",
    "# ----- format setting -----\n",
    "axs.format(\n",
    "abc=True,\n",
    "abcloc = 'ul',\n",
    "#----- 地图底图设置 -----\n",
    "# reso = 'x-hi',\n",
    "reso = 'med',\n",
    "# coast = False,\n",
    "coast = True,\n",
    "coastlinewidth = 0.4,\n",
    "borders = False,\n",
    "lakes = False,\n",
    "land  = False,\n",
    "ocean = False,\n",
    "# cartopyautoextent = True, \n",
    "# borderslinewidth=.5,\n",
    "labels = True,\n",
    "longrid  = True,\n",
    "latgrid  = True,\n",
    "#-----GEO axis-----\n",
    "lonlim=(70, 140), latlim=(15, 55),\n",
    "gridlabelsize = 5,\n",
    "gridminor = True,\n",
    "lonlocator = np.arange(70,142,10),\n",
    "latlocator = np.arange(5,65+2,10),\n",
    "lonminorlocator = np.arange(70,140+2,2),\n",
    "latminorlocator = np.arange(5,65+2,2),\n",
    "#-----line label-----\n",
    "suptitle=\"interannual TCC RMSE STD\",\n",
    ")\n",
    "\n",
    "#----- save figure -----\n",
    "fig.patch.set_facecolor('white')\n",
    "fig.savefig('./output_pic/t2m_InterannualStats_2022.01.12.png', dpi=600, facecolor= \"white\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5d125e8d1f62ef65bf14791ddcc54379be6b4b51969987cfa8a226a16aec3b4e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('proplot0528': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
