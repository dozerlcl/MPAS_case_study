{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import proplot as pplt\n",
    "from scipy.fftpack import * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2021.08.08\n",
    "\n",
    "尝试使用proplot绘制平均图\n",
    "\n",
    "温度观测状况不变，CN05.1只在中国大陆有分析结果，仍然使用原本的数据\n",
    "\n",
    "2022.02.13\n",
    "\n",
    "计算MJJA的平均态，并且绘制气温的最大、最小、平均的状态\n",
    "\n",
    "使用PD制表，写出CSV表格说明平均态的统计结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据读入"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 直接获取此前使用1hr间隔计算的tmax tmin tmean 使用路径：\n",
    "\n",
    "dir_in = \"/raid52/yycheng/MPAS/REFERENCE/TEMP_DATA/mask_t2m/mask_res/\"\n",
    "\n",
    "- 使用三小时取样计算的t2m\n",
    "\n",
    "dir_in = \"/raid52/yycheng/MPAS/REFERENCE/TEMP_DATA/mask_t2m/mask_res_3hr/\"\n",
    "\n",
    "- 使用六小时取样计算t2m\n",
    "\n",
    "dir_in = \"/raid52/yycheng/MPAS/REFERENCE/TEMP_DATA/mask_t2m/mask_res_6hr/\"\n",
    "\n",
    "最后进行混合使用 mean 使用 6HR取样计算 min max使用1HR计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = {} # 放置所有变量的字典\n",
    "# read mean\n",
    "dir_in = \"/raid52/yycheng/MPAS/REFERENCE/TEMP_DATA/mask_t2m/mask_res/\"\n",
    "filename_obs  = \"mask_sel_CN05.1_Tm_1961_2018_daily_025x025.nc\"\n",
    "filename_vr     = \"mask_mean_t2m_98-17_VR.nc\"\n",
    "filename_rcm    = \"mask_mean_t2m_98-17_RCM.nc\"\n",
    "ds_or = {}\n",
    "ds_or['obs'] = xr.open_dataset(dir_in + filename_obs)\n",
    "ds_or['vr']     = xr.open_dataset(dir_in + filename_vr)\n",
    "ds_or['rcm']    = xr.open_dataset(dir_in + filename_rcm  )\n",
    "var['mean'] = {}\n",
    "var['mean']['obs'] = ds_or['obs']['tm']#[:,  :, :]\n",
    "var['mean']['vr'] = ds_or['vr']['t2m'] - 273.15\n",
    "var['mean']['rcm'] = ds_or['rcm']['t2m'] - 273.15\n",
    "\n",
    "# 2022.02.15 min max切换到六小时的计算结果\n",
    "dir_in = \"/raid52/yycheng/MPAS/REFERENCE/TEMP_DATA/mask_t2m/mask_res_6hr/\"\n",
    "\n",
    "# max\n",
    "filename_obs  = \"mask_sel_CN05.1_Tmax_1961_2018_daily_025x025.nc\"\n",
    "filename_vr     = \"mask_max_t2m_98-17_VR.nc\"\n",
    "filename_rcm    = \"mask_max_t2m_98-17_RCM.nc\"\n",
    "ds_or = {}\n",
    "ds_or['obs'] = xr.open_dataset(dir_in + filename_obs)\n",
    "ds_or['vr']     = xr.open_dataset(dir_in + filename_vr)\n",
    "ds_or['rcm']    = xr.open_dataset(dir_in + filename_rcm  )\n",
    "var['max'] = {}\n",
    "var['max']['obs'] = ds_or['obs']['tmax']#[:,  :, :]\n",
    "var['max']['vr'] = ds_or['vr']['t2m'] - 273.15\n",
    "var['max']['rcm'] = ds_or['rcm']['t2m'] - 273.15\n",
    "\n",
    "# min\n",
    "filename_obs  = \"mask_sel_CN05.1_Tmin_1961_2018_daily_025x025.nc\"\n",
    "filename_vr     = \"mask_min_t2m_98-17_VR.nc\"\n",
    "filename_rcm    = \"mask_min_t2m_98-17_RCM.nc\"\n",
    "ds_or = {}\n",
    "ds_or['obs'] = xr.open_dataset(dir_in + filename_obs)\n",
    "ds_or['vr']     = xr.open_dataset(dir_in + filename_vr)\n",
    "ds_or['rcm']    = xr.open_dataset(dir_in + filename_rcm  )\n",
    "var['min'] = {}\n",
    "var['min']['obs'] = ds_or['obs']['tmin']#[:,  :, :]\n",
    "var['min']['vr'] = ds_or['vr']['t2m'] - 273.15\n",
    "var['min']['rcm'] = ds_or['rcm']['t2m'] - 273.15\n",
    "\n",
    "# change coords\n",
    "var_list = ['obs', 'vr', 'rcm']\n",
    "for i in ['mean', 'max', 'min']:\n",
    "    for j in var_list:\n",
    "        rename_dict = dict(zip(var[i][j].coords.keys(), var[i]['obs'].coords.keys()))\n",
    "        # for rename_i in rename_dict:\n",
    "            # print(rename_i + \" -----converting to----- \" + rename_dict[rename_i])\n",
    "\n",
    "        var[i][j] = var[i][j].rename(rename_dict)\n",
    "        var[i][j]._coords = var[i]['obs']._coords\n",
    "        var[i][j] = var[i][j].rename(j)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算平均态\n",
    "调整到MJJA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_selmonth = {}\n",
    "var_selmonth['mjja'] = {}\n",
    "for var_name in ['mean', 'max', 'min']:\n",
    "    var_selmonth['mjja'][var_name] = {}\n",
    "    for mod_name in ['obs', 'vr', 'rcm']:\n",
    "        time_idx_mjja = var[var_name][mod_name].time.dt.month.isin([5,6,7,8])\n",
    "        var_selmonth['mjja'][var_name][mod_name] = var[var_name][mod_name].isel(time = time_idx_mjja).mean(dim = 'time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算指标"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算制图表格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_dict():\n",
    "    from collections import defaultdict\n",
    "    return defaultdict(nested_dict)\n",
    "# 进行mask，并且整理成1D数组，得到1D-pattern，用于后续的计算\n",
    "# 计算指数的平均值\n",
    "var_1d = nested_dict()\n",
    "for iseason in ['mjja']:\n",
    "    for var_name in ['mean', 'max', 'min']:\n",
    "        for mod_name in ['obs', 'vr', 'rcm']:\n",
    "            # 获取1D的平均态 并以RCM为基础进行NAN的MASK\n",
    "            rcm_not_nan = ( ~np.isnan(var_selmonth['mjja']['mean']['rcm'])) &\\\n",
    "                 (~np.isnan(var_selmonth['mjja']['mean']['obs'])) &\\\n",
    "                 (~np.isnan(var_selmonth['mjja']['mean']['vr']) )\n",
    "            var_1d_temp = xr.where(rcm_not_nan, var_selmonth[iseason][var_name][mod_name], np.nan).values.ravel()\n",
    "            var_1d[iseason][var_name][mod_name] = var_1d_temp[~np.isnan(var_1d_temp)]\n",
    "            # shape check\n",
    "            # print(var_1d[iseason][var_name][mod_name].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skill_metrics as sm\n",
    "# 计算泰勒图诸要素 到字典taylor_ts中\n",
    "\n",
    "# 进行mask，并且整理成1D数组，得到1D-pattern，用于后续的计算\n",
    "# 计算指数的平均值\n",
    "taylor_space = nested_dict()\n",
    "for iseason in ['mjja']:\n",
    "    for var_name in ['mean', 'max', 'min']:\n",
    "        for mod_name in ['obs', 'vr', 'rcm']:\n",
    "            temp_obs = var_1d[iseason][var_name]['obs']\n",
    "            temp_mod = var_1d[iseason][var_name][mod_name]\n",
    "            # taylor count\n",
    "            taylor_space[iseason][var_name][mod_name] = sm.taylor_statistics(temp_mod, temp_obs)\n",
    "            # normalized 注意先后顺序，先归一化CRMSD，再SDEV，否则用归一化后的SDEV计算RMSD会出现问题\n",
    "            # taylor_space[iseason][var_name][mod_name]['crmsd'] = taylor_space[iseason][var_name][mod_name]['crmsd'] / taylor_space[iseason][var_name][mod_name]['sdev'][0]\n",
    "            # taylor_space[iseason][var_name][mod_name]['sdev'] = taylor_space[iseason][var_name][mod_name]['sdev'] / taylor_space[iseason][var_name][mod_name]['sdev'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 合并表格并写出csv文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_templist = []\n",
    "ind = np.array([0]) # index的整数\n",
    "for iseason in ['mjja']:\n",
    "    for var_name in ['mean', 'max', 'min']:\n",
    "        for mod_name in ['obs', 'vr', 'rcm']:\n",
    "            temp_ccoef = taylor_space[iseason][var_name][mod_name]['ccoef'][1]\n",
    "            temp_crmsd = taylor_space[iseason][var_name][mod_name]['crmsd'][1]\n",
    "            temp_sdev  = taylor_space[iseason][var_name][mod_name]['sdev'][1]\n",
    "            temp_mean  = var_1d[iseason][var_name][mod_name].mean()\n",
    "            # temp_bias  = var_1d[iseason][var_name][mod_name].mean() - var_1d[iseason][var_name]['obs'].mean()\n",
    "            temp_bias  = sm.bias(var_1d[iseason][var_name][mod_name], var_1d[iseason][var_name]['obs'])\n",
    "            temp_rmsd  = sm.rmsd(var_1d[iseason][var_name][mod_name], var_1d[iseason][var_name]['obs'])\n",
    "            \n",
    "            pd_templist.append( pd.DataFrame(data = [[var_name, mod_name, temp_mean, temp_bias, temp_ccoef, temp_crmsd, temp_rmsd, temp_sdev]], \\\n",
    "                columns = ['variable','model','mean', 'bias','ccoef','crmsd','rmsd','sdev'], index=  ind) )\n",
    "            ind = ind + 1\n",
    "\n",
    "# 合并表格并写出\n",
    "table_pdconcat = pd.concat(pd_templist)\n",
    "table_pdconcat.to_csv(\"./output_table/t2m_SpatialTaylor.2022.02.15.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 绘图部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 国内政区图的绘制\n",
    "# Load the border data, CN-border-La.dat is download from\n",
    "# https://gmt-china.org/data/CN-border-La.dat\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.io.shapereader as shpreader\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.patches as mpatches\n",
    "import cmaps\n",
    "\n",
    "cn_border_file = \"/m2data2/yycheng/data_stage/CN-border/CN-border_line/CN-border-La.dat\"\n",
    "with open(cn_border_file) as src:\n",
    "    context = src.read()\n",
    "    blocks = [cnt for cnt in context.split('>') if len(cnt) > 0]\n",
    "    borders = [np.fromstring(block, dtype=float, sep=' ') for block in blocks]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 画图renew\n",
    "#### 2021.08.08\n",
    "cn_border_file + shapefile ，但是存在重叠，尝试消除掉China边界，但是其他邻国边界无法处理；\n",
    "#### 2021.08.09\n",
    "不使用cn_border_file ，使用shapefile + coast_line（proplot自带） 的办法\n",
    "shapefile有一些重叠，不绘制行政区\n",
    "shapefile重新进行绘制，考虑来自 domain_info 中测试的多个shape file中挑选出地资所（改变了prj方式，具体查看prj后缀文件）进行使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def border_plot(axs):\n",
    "    \"\"\"\n",
    "    进行行政区划的绘制，通过shapefilereader绘制存档的shp文件，需要传入axs，并逐个绘制\n",
    "    比较消耗时间，调整完毕后最后添加边界的绘制\n",
    "    \"\"\"\n",
    "    ##---- 直接绘图，从边界文件添加\n",
    "    # for ax_ind in axs:\n",
    "    # for line in borders:\n",
    "    #     axs.plot(line[0::100], line[1::100], lw = 0.5, color='gray',transform=ccrs.Geodetic())\n",
    "    #     axs.plot(line[0::10], line[1::10], lw = 0.4, color='black',transform=ccrs.Geodetic())\n",
    "    ##---- 使用shp文件添加\n",
    "        # shapefile数据下载的位置：\n",
    "    # http://gaohr.win/site/blogs/2017/2017-04-18-GIS-basic-data-of-China.html\n",
    "    world_border_shapefile = \"/m2data2/yycheng/data_stage/CN-border/World/country.shp\"\n",
    "    river_border_shapefile =  \"/raid52/yycheng/MPAS/REFERENCE/MODEL_CONSTANT/R1/\" + \"hyd1_4l.shp\"\n",
    "    southsea_shapefile     = \"/m2data2/yycheng/data_stage/CN-border/SouthSea/\" + \"southsea_island.shp\"\n",
    "    ninelines_shapefile     = \"/m2data2/yycheng/data_stage/CN-border/SouthSea/\" + \"nine_lines.shp\"\n",
    "    ## 来源： 沛沛的诸省 + 诸岛\n",
    "    bou24p_shapefile     = \"/m2data2/yycheng/data_stage/CN-border/peipeihelp/\" + \"bou2_4p.shp\"\n",
    "    ## 来源： https://www.resdc.cn/data.aspx?DATAID=200\n",
    "    province_shapefile     = \"/m2data2/yycheng/data_stage/CN-border/CN-sheng/\" + \"change_proj_CN-sheng-A.shp\"\n",
    "\n",
    "    for ax in axs:\n",
    "        # world     = shpreader.Reader(world_border_shapefile).geometries()\n",
    "        # river     = shpreader.Reader(river_border_shapefile).geometries()\n",
    "        river     = shpreader.Reader(river_border_shapefile, encoding = \"gbk\")\n",
    "        # bou24p    = shpreader.Reader(bou24p_shapefile).geometries()\n",
    "        ninelines = shpreader.Reader(ninelines_shapefile).geometries()\n",
    "        province  = shpreader.Reader(province_shapefile).geometries()\n",
    "        # ax.add_geometries(river, ccrs.PlateCarree(), facecolor='none', edgecolor='b', linewidth=0.4, zorder=1)\n",
    "        # ax.add_geometries(world, ccrs.PlateCarree(), facecolor='none', edgecolor='k', linewidth=0.4, zorder=1)\n",
    "        # ax.add_geometries(bou24p, ccrs.PlateCarree(), facecolor='none', edgecolor='k', linewidth=0.6, zorder=1) # 沛沛map\n",
    "        ax.add_geometries(province, ccrs.PlateCarree(), facecolor='none', edgecolor='k', linewidth=0.6, zorder=1) # 地资所\n",
    "        ax.add_geometries(ninelines, ccrs.PlateCarree(), facecolor='none', edgecolor='k', linewidth=0.6, zorder=1)\n",
    "        # 绘制部分的shapefile\n",
    "        for region in river.records():\n",
    "            if (region.attributes['NAME'] in ['黄河','长江']):\n",
    "                # print(\"----- draw river! -----\")\n",
    "                # 此处需要使用 [] 让region.geometry可以迭代\n",
    "                ax.add_geometries([region.geometry], ccrs.PlateCarree(), facecolor='none', edgecolor='b', linewidth=0.4, zorder=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_southchinasea(axs):\n",
    "    '''\n",
    "    用于制作南海小图的axes，偷懒使用上面绘制的borders绘制地图的边界状况，视情况准备其他边界数据\n",
    "    需要特别对新axes进行绘制\n",
    "    '''\n",
    "    for axs_single in axs:\n",
    "        axs_small = axs_single.inset_axes(bounds = (0.85, 0.02, 0.15, 0.35), transform = 'axes', proj = 'cyl', zoom = False)\n",
    "\n",
    "        axs_small.format(\n",
    "        lonlim=(107, 123), latlim=(0, 25),\n",
    "        #----- 地图底图设置 -----\n",
    "        reso = 'med',\n",
    "        coast = True,\n",
    "        coastlinewidth = 0.4,\n",
    "        borders = False,\n",
    "        lakes = False,\n",
    "        land  = False,\n",
    "        ocean = False,\n",
    "        labels = False,\n",
    "        longrid  = False,\n",
    "        latgrid  = False,\n",
    "        #-----GEO axis-----\n",
    "        )\n",
    "        # 自己设置的绘制中国区域的border_plot\n",
    "        border_plot([axs_small])\n",
    "        return axs_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import proplot as plot\n",
    "from matplotlib import pyplot as plt\n",
    "import proplot as plot\n",
    "import collections\n",
    "# ----- get filter vars coords-----\n",
    "\n",
    "lon = var_selmonth['mjja']['mean']['vr'].lon.values\n",
    "lat = var_selmonth['mjja']['mean']['vr'].lat.values\n",
    "\n",
    "#----- change font -----\n",
    "pplt.rc['font.serif'] = 'Arial'\n",
    "\n",
    "#----- create plot -----\n",
    "# fig, axs = plot.subplots(ncols=3 ,nrows=3, proj=('cyl'), journal = 'agu2', share = True)\n",
    "fig, axs = plot.subplots(ncols=3 ,nrows=3, proj=('cyl'), figwidth = '190mm', figheight = '150mm', share = True, tight = True)\n",
    "# fig, axs = plot.subplots(ncols=3 ,nrows=3, proj=('cyl'), share = True, hspace = (0,0), wspace = (0,0))\n",
    "# fig, axs = plot.subplots(ncols=3 ,nrows=3, proj=('cyl'))\n",
    "m_contour_list = [] # 用于保存contour设置，后续设置colorbar使用\n",
    "\n",
    "#----- 添加海洋以及行政区划 -----\n",
    "border_plot(axs)\n",
    "\n",
    "def nested_dict():\n",
    "    return collections.defaultdict(nested_dict)\n",
    "mcontourf_dict = nested_dict()\n",
    "#----- colorbar ticks 统一设置 -----\n",
    "cmap_mean      = cmaps.BkBlAqGrYeOrReViWh200\n",
    "# cmap_diff = cmaps.cmp_flux \n",
    "cmap_diff = cmaps.ncl_default \n",
    "\n",
    "# mean_ticks = np.concatenate((np.linspace(0,12,13), np.linspace(14,34,6)), axis=0)\n",
    "mean_ticks = np.linspace(-5,35,int(40/1) + 1)\n",
    "diff_ticks = np.linspace(-5, 5, 21)\n",
    "print(\"----- tick levels is : \" + str(mean_ticks))\n",
    "\n",
    "#----- plot contourf and titile axs ------\n",
    "\n",
    "###----- main plot -----\n",
    "plot_ind = 0\n",
    "for var_name in ['mean', 'max', 'min']:\n",
    "    for mod_name in ['obs','vr','rcm']:\n",
    "        axs_small_temp = add_southchinasea([axs[plot_ind]]) # 生成南海小图的axs\n",
    "        if (mod_name == 'obs'):\n",
    "            mcontourf_dict['mjja'][var_name][mod_name] = axs[plot_ind].contourf(lon, lat, var_selmonth['mjja'][var_name][mod_name].values,\\\n",
    "                levels = mean_ticks, cmap = cmap_mean, extend = 'both')\n",
    "            # 添加南海小图的等值线绘制，方法较为原始，直接赋值上文\n",
    "            axs_small_temp.contourf(lon, lat, var_selmonth['mjja'][var_name][mod_name].values,\\\n",
    "            levels = mean_ticks, cmap = cmap_mean, extend = 'both')\n",
    "        else:\n",
    "            mcontourf_dict['mjja'][var_name][mod_name] = axs[plot_ind].contourf(lon, lat, var_selmonth['mjja'][var_name][mod_name].values - var_selmonth['mjja'][var_name]['obs'].values,\\\n",
    "                levels = diff_ticks, cmap = cmap_diff, extend = 'both')\n",
    "            # 添加南海小图的等值线绘制，方法较为原始，直接赋值上文\n",
    "            axs_small_temp.contourf(lon, lat, var_selmonth['mjja'][var_name][mod_name].values - var_selmonth['mjja'][var_name]['obs'].values,\\\n",
    "                levels = diff_ticks, cmap = cmap_diff, extend = 'both')\n",
    "\n",
    "        plot_ind = plot_ind + 1\n",
    "\n",
    "#----- add color bar-----\n",
    "\n",
    "fig.colorbar(mcontourf_dict['mjja']['mean']['obs'], loc='b', width=0.1, extend = 'both',length = 0.9,\\\n",
    "ticklabelsize=5,labelsize = 7,ticks=mean_ticks[::2], title='near-surface air temperature ' + r\"$[^\\circ C$]\")\n",
    "\n",
    "fig.colorbar(mcontourf_dict['mjja']['mean']['vr'], loc='b', width=0.1, extend = 'both',length = 0.9,\\\n",
    "ticklabelsize=5,labelsize = 7,ticks=diff_ticks, title='bias ' + r\"$[^\\circ C$]\")\n",
    "\n",
    "# ----- format setting -----\n",
    "axs.format(\n",
    "abc=True,\n",
    "abcloc = 'ul',\n",
    "#----- 地图底图设置 -----\n",
    "# reso = 'x-hi',\n",
    "reso = 'med',\n",
    "# coast = False,\n",
    "coast = True,\n",
    "coastlinewidth = 0.4,\n",
    "borders = False,\n",
    "lakes = False,\n",
    "land  = False,\n",
    "ocean = False,\n",
    "# cartopyautoextent = True, \n",
    "# borderslinewidth=.5,\n",
    "labels = False,\n",
    "longrid  = True,\n",
    "latgrid  = True,\n",
    "#-----GEO axis-----\n",
    "lonlim=(72, 136), latlim=(15, 55),\n",
    "gridlabelsize = 5,\n",
    "gridminor = True,\n",
    "lonlocator = np.arange(70,142,10),\n",
    "latlocator = np.arange(15,55+2,10),\n",
    "lonminorlocator = np.arange(70,140+2,2),\n",
    "latminorlocator = np.arange(15,55+2,2),\n",
    "#-----line label-----\n",
    "# linewidth = 0.5,\n",
    "# suptitle=\"surface air temperature\",\n",
    "toplabels=('CN05.1', 'VR', 'RCM'),\n",
    "leftlabels=('T2m','T2max','T2min'),\n",
    "# leftlabelsize = 6.,\n",
    "rc_kw = {'leftlabel.rotation':90.},\n",
    ")\n",
    "\n",
    "# 合并子图之后控制边界的labels绘制\n",
    "axs[:-1,0].format(labels = True, lonlabels = False, latlabels = True)\n",
    "axs[-1,1:].format(labels = True, lonlabels = True, latlabels = False)\n",
    "axs[-1,0].format(labels = True, lonlabels = True, latlabels = True)\n",
    "\n",
    "#----- save figure -----\n",
    "fig.patch.set_facecolor('white')\n",
    "fig.savefig('./output_pic/t2m_meanstates.2022.05.02.jpg', dpi=600, format = 'jpg', facecolor = 'white', bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "da0469cb1653dac5810650c6f9c12d7c46a389e85e448c305f1477fdb1af5288"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('proplot0528': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
