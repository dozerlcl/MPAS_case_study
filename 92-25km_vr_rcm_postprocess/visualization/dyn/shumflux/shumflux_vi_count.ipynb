{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# %matplotlib inlineb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "2021.07.06\n",
    "\n",
    "计算水汽通量的积分值，在等压面上计算并积分\n",
    "\n",
    "有冗长的整理部分，通过dict选取变量，并且整理到相应的am，jja上，再进行计算，绘制平均\n",
    "\n",
    "数据整理部分适用于所有从MPAS中convert出来用于和ERA5I进行环流场上对比的部分\n",
    "\n",
    "2021.08.16\n",
    "\n",
    "修改到更大的范围上, 从200hPa开始垂直积分"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 数据读取\n",
    "读取的ERA5I数据顺便处理为了和MPAS相同的坐标之后再进行的输出"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ds_wind = {}\n",
    "ds_qv   = {}\n",
    "\n",
    "# diag数据包含9-1，需要去掉尾部\n",
    "dir_in = \"/raid52/yycheng/MPAS/VR_postprocess/VR_merge_large/ke_daily_vi/\"\n",
    "ds_wind['vr'] = xr.open_mfdataset(dir_in + \"*_VR_ke_daily_vi.nc\")\n",
    "ds_wind['vr'] = ds_wind['vr'].sel(Time = ds_wind['vr'].Time.dt.month.isin([4,5,6,7,8]))\n",
    "dir_in = \"/raid52/yycheng/MPAS/VR_postprocess/VR_merge_large/hum_theta_daily_vi/\"\n",
    "ds_qv['vr'] = xr.open_mfdataset(dir_in + \"*_VR_hum_theta_daily_vi.nc\")\n",
    "ds_qv['vr'] = ds_qv['vr'].sel(Time = ds_qv['vr'].Time.dt.month.isin([4,5,6,7,8]))\n",
    "\n",
    "dir_in = \"/raid52/yycheng/MPAS/RCM_postprocess/RCM_merge_large/ke_daily_vi/\"\n",
    "ds_wind['rcm'] = xr.open_mfdataset(dir_in + \"*_RCM_ke_daily_vi.nc\")\n",
    "ds_wind['rcm'] = ds_wind['rcm'].sel(Time = ds_wind['rcm'].Time.dt.month.isin([4,5,6,7,8]))\n",
    "dir_in = \"/raid52/yycheng/MPAS/RCM_postprocess/RCM_merge_large/hum_theta_daily_vi/\"\n",
    "ds_qv['rcm'] = xr.open_mfdataset(dir_in + \"*_RCM_hum_theta_daily_vi.nc\")\n",
    "ds_qv['rcm'] = ds_qv['rcm'].sel(Time = ds_qv['rcm'].Time.dt.month.isin([4,5,6,7,8]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 添加ERA5I观测数据\n",
    "ds_wind['obs'] = {}\n",
    "\n",
    "# 切换 ERA5I 坐标到MPAS输出结果，方便转换\n",
    "\n",
    "rename_dict = {\"level\":\"plevels\", \"lon\":\"longitude\", \"lat\":\"latitude\", \"time\":\"Time\"}\n",
    "# ds_wind['obs']['uReconstructZonal'].assign_coords(Time = Time)\n",
    "# show converting coords\n",
    "for rename_i in rename_dict:\n",
    "    print(rename_i + \" -----converting to----- \" + rename_dict[rename_i])\n",
    "# 读取数据后就整理坐标，和RCM的坐标一致，之后再进行计算\n",
    "dir_in = \"/raid52/yycheng/MPAS/REFERENCE/ERA5I_NC/ERA5I_NC_daily_large/u_98-17_daily/\"\n",
    "ds_wind['obs'][\"uReconstructZonal\"] = xr.open_dataset(dir_in + \"merge_uwnd_98-17_daily.nc\")\\\n",
    "    .rename(rename_dict).assign_coords(ds_qv['rcm']['qv'].coords)['uwnd']\n",
    "\n",
    "dir_in = \"/raid52/yycheng/MPAS/REFERENCE/ERA5I_NC/ERA5I_NC_daily_large/v_98-17_daily/\"\n",
    "ds_wind['obs'][\"uReconstructMeridional\"] = xr.open_dataset(dir_in + \"merge_vwnd_98-17_daily.nc\")\\\n",
    "    .rename(rename_dict).assign_coords(ds_qv['rcm']['qv'].coords)['vwnd']\n",
    "\n",
    "dir_in = \"/raid52/yycheng/MPAS/REFERENCE/ERA5I_NC/ERA5I_NC_daily_large/shum_98-17_daily/\"\n",
    "ds_qv['obs'] = xr.open_dataset(dir_in + \"merge_shum_98-17_daily.nc\").rename(rename_dict).assign_coords(ds_qv['rcm']['qv'].coords)\n",
    "ds_qv['obs'] = ds_qv['obs'].rename({\"shum\":\"qv\"})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# ----- select data range -----\n",
    "lat_sel     = (ds_qv['vr'].latitude >= 5) & (ds_qv['vr'].latitude <= 60)\n",
    "lon_sel     = (ds_qv['vr'].longitude >= 70) & (ds_qv['vr'].longitude <= 140)\n",
    "plevels_sel = (ds_qv['vr'].plevels >= 200) & (ds_qv['vr'].plevels <= 925)\n",
    "\n",
    "time_year    = (ds_qv['vr'].Time.dt.year >= 1998) # 时次相对较长，一开始使用1998年一年进行尝试\n",
    "time_sel_am     = ds_qv['vr'].Time.dt.month.isin([4,5])\n",
    "time_sel_jja    = ds_qv['vr'].Time.dt.month.isin([6,7,8])\n",
    "\n",
    "sel_dict = {}\n",
    "sel_dict['am']    = {'longitude':lon_sel, \"latitude\":lat_sel, \"plevels\":plevels_sel, \"Time\":(time_sel_am & time_year)}\n",
    "sel_dict['jja']   = {'longitude':lon_sel, \"latitude\":lat_sel, \"plevels\":plevels_sel, \"Time\":(time_sel_jja & time_year)}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# ----- 选取变量 -----\n",
    "mod_list    = ['obs', 'vr', 'rcm']\n",
    "season_list = ['am', 'jja']\n",
    "# 存放整理后变量的字典\n",
    "u_sel = {}\n",
    "v_sel = {}\n",
    "qv_sel = {}\n",
    "\n",
    "for imod in mod_list:\n",
    "    # print(imod)\n",
    "    u_sel[imod]  = {}\n",
    "    v_sel[imod]  = {}\n",
    "    qv_sel[imod] = {}\n",
    "    for iseason in season_list:\n",
    "        # print(iseason)\n",
    "        u_sel[imod][iseason]  = ds_wind[imod]['uReconstructZonal'].isel(sel_dict[iseason])\n",
    "        v_sel[imod][iseason]  = ds_wind[imod]['uReconstructMeridional'].isel(sel_dict[iseason])\n",
    "        qv_sel[imod][iseason] = ds_qv[imod]['qv'].isel(sel_dict[iseason])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 计算垂直积分\n",
    "\n",
    "保存到变量 uflux_vi 和 vflux_vi 之中"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# count flux\n",
    "uflux = {}\n",
    "vflux = {}\n",
    "# count flux vertical integration\n",
    "uflux_vi = {}\n",
    "vflux_vi = {}\n",
    "sel_plevels_val = u_sel['vr']['am'].plevels\n",
    "\n",
    "for imod in mod_list:\n",
    "    print(imod)\n",
    "    uflux[imod] = {}\n",
    "    vflux[imod] = {}\n",
    "    uflux_vi[imod] = {}\n",
    "    vflux_vi[imod] = {}\n",
    "    for iseason in season_list:\n",
    "        print(iseason)\n",
    "        uflux[imod][iseason] = u_sel[imod][iseason] * qv_sel[imod][iseason]\n",
    "        vflux[imod][iseason] = v_sel[imod][iseason] * qv_sel[imod][iseason]\n",
    "        plevels_axis = list(uflux[imod][iseason].dims).index('plevels')\n",
    "        # remove nan values\n",
    "        uflux[imod][iseason] = np.where(np.isnan(uflux[imod][iseason]), 0, uflux[imod][iseason])\n",
    "        vflux[imod][iseason] = np.where(np.isnan(vflux[imod][iseason]), 0, vflux[imod][iseason])\n",
    "        # find plevels axis location\n",
    "        uflux_vi[imod][iseason] = np.trapz(uflux[imod][iseason], sel_plevels_val, axis = plevels_axis)\n",
    "        vflux_vi[imod][iseason] = np.trapz(vflux[imod][iseason], sel_plevels_val, axis = plevels_axis)\n",
    "# "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 整理绘图所使用的坐标变量\n",
    "lat  = u_sel['vr']['jja'].latitude\n",
    "lon  = u_sel['vr']['jja'].longitude\n",
    "time = u_sel['vr']['jja'].Time\n",
    "time_am = u_sel['vr']['am'].Time\n",
    "time_jja = u_sel['vr']['jja'].Time\n",
    "time_iseason = {}\n",
    "time_iseason['am'] = time_am\n",
    "time_iseason['jja'] = time_jja"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 临时文件\n",
    "\n",
    "进行文件的输出部分 计算时间太长 需要一个半小时\n",
    "\n",
    "进行flux垂直积分之后结果的输出，放置到 /raid52/yycheng/MPAS/REFERENCE/TEMP_DATA/dyn/shum_flux 之中\n",
    "\n",
    "合并了RCM的边界上的空缺，但是文件输出都是手动进行的，注意对变量、时次进行调整"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 处理RCM 中边界的NAN的问题，合并成同样的fillvalues，之后赋值为 -1e30\n",
    "for iseason in season_list:\n",
    "    rcm_nan_index = (uflux_vi['rcm'][iseason][:,:,:] > 1e10)\n",
    "    uflux_vi['rcm'][iseason][rcm_nan_index] = -1e30\n",
    "    vflux_vi['rcm'][iseason][rcm_nan_index] = -1e30"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 临时存放变量\n",
    "# uflux_vi['obs']['am'].shape\n",
    "for iseason in ['am','jja']:\n",
    "    uflux_vi_tonc = {}\n",
    "    vflux_vi_tonc = {}\n",
    "    encoding = {}\n",
    "    for imod in mod_list:\n",
    "        uflux_vi_tonc[imod] = xr.DataArray(uflux_vi[imod][iseason], coords=[time_iseason[iseason],lat,lon], name=imod)\n",
    "        # 添加NAN时需要\n",
    "        encoding[imod] = {\"_FillValue\":-1e30}\n",
    "\n",
    "    ds_out = xr.merge(list( uflux_vi_tonc.values() ))\n",
    "    ds_out.fillna(-1e30)\n",
    "\n",
    "    dir_out = \"/raid52/yycheng/MPAS/REFERENCE/TEMP_DATA_large/dyn/shum_flux/\"\n",
    "    ds_out.to_netcdf(dir_out + \"shum_uflux_\"+iseason+\".nc\", encoding = encoding)\n",
    "    ds_out.close()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "da0469cb1653dac5810650c6f9c12d7c46a389e85e448c305f1477fdb1af5288"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.2 64-bit ('proplot0528': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}