{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import proplot as pplt\n",
    "from scipy.fftpack import * "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "2021.08.08\n",
    "\n",
    "尝试使用proplot绘制平均图\n",
    "\n",
    "使用pre_process/merge_cmorph_cn051.ipynb 下合并掉cmorph以及cmorph的数据\n",
    "\n",
    "绘制每个格点年际时间序列，分为am和jja时段的二十年的年际时间序列的CORR以及RMSD"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 数据读入"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dir_in = \"/raid52/yycheng/MPAS/REFERENCE/TEMP_DATA_large/pre/ordata/\"\n",
    "filename_obs  = \"obsmerge_pre_98-17.nc\"\n",
    "filename_vr     = \"vr_pre_98-17.nc\"\n",
    "filename_rcm    = \"rcm_pre_98-17.nc\"\n",
    "\n",
    "ds_or = {}\n",
    "ds_or['obs'] = xr.open_dataset(dir_in + filename_obs)\n",
    "ds_or['vr']     = xr.open_dataset(dir_in + filename_vr)\n",
    "ds_or['rcm']    = xr.open_dataset(dir_in + filename_rcm  )\n",
    "# 提取变量\n",
    "var = {}\n",
    "var['obs'] = ds_or['obs']['premerge']#[:,  :, :]\n",
    "var['vr'] = ds_or['vr']['precip_MPAS']\n",
    "var['rcm'] = ds_or['rcm']['precip_MPAS']\n",
    "\n",
    "var['obs'] = var['obs'].reset_coords(names = 'lev', drop = True) # 去除掉obs中多余的lev coords\n",
    "\n",
    "# change coords\n",
    "var_list = ['obs', 'vr', 'rcm']\n",
    "for i in var_list:\n",
    "    rename_dict = dict(zip(var[i].coords.keys(), var['obs'].coords.keys()))\n",
    "#     # show converting coords\n",
    "    for rename_i in rename_dict:\n",
    "        print(rename_i + \" -----converting to----- \" + rename_dict[rename_i])\n",
    "\n",
    "    var[i] = var[i].rename(rename_dict)\n",
    "    var[i]._coords = var['obs']._coords\n",
    "    var[i] = var[i].rename(i)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "var_selmonth = {}\n",
    "var_selmonth['am'] = {}\n",
    "var_selmonth['jja'] = {}\n",
    "\n",
    "time_idx_am = var['obs'].time.dt.month.isin([4,5])\n",
    "time_idx_jja = var['obs'].time.dt.month.isin([6,7,8])\n",
    "\n",
    "for mod_name in ['obs', 'vr', 'rcm']:\n",
    "    var_selmonth['am'][mod_name]  = var[mod_name].isel(time = time_idx_am)\n",
    "    var_selmonth['jja'][mod_name] = var[mod_name].isel(time = time_idx_jja)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 计算年际相关系数"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 获取年际时间序列 var_interannual{} dict\n",
    "var_interannual = {}\n",
    "time_for_groupby = {}\n",
    "time_for_groupby['am'] = var_selmonth['am']['vr'].time.dt.year\n",
    "time_for_groupby['jja'] = var_selmonth['jja']['vr'].time.dt.year\n",
    "\n",
    "for iseason in ['am', 'jja']:\n",
    "    var_interannual[iseason] = {}\n",
    "    for mod_name in ['obs', 'vr', 'rcm']:\n",
    "        var_interannual[iseason][mod_name] = var_selmonth[iseason][mod_name].groupby(time_for_groupby[iseason]).mean(dim = 'time')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def scipy_count_corr_2d(a,b):\n",
    "    '计算两个3D序列在时间维上的相关性，使用scipy逐个格点的计算，获取pvalues,输入数组a,b 按照 time x lat x lon的方式进行排列'\n",
    "    '如果第一个时次出现了np.nan ,那么就对这个格点赋值为nan'\n",
    "    import numpy as np\n",
    "    from scipy import stats\n",
    "\n",
    "    dim1 = a.shape[1]\n",
    "    dim2 = a.shape[2]\n",
    "    pvalues = np.empty(shape = a.shape[1:])\n",
    "    corrvalues = np.empty(shape = a.shape[1:])\n",
    "    # np.corrcoef?\n",
    "    for ilat in range(0, dim1):\n",
    "        for ilon in range(0, dim2):\n",
    "            if ( (np.isnan(a[0,ilat,ilon])) | (np.isnan(b[0,ilat,ilon])) ):\n",
    "                corrvalues[ilat, ilon], pvalues[ilat, ilon] = np.nan, np.nan\n",
    "                continue    \n",
    "            corrvalues[ilat, ilon], pvalues[ilat, ilon] \\\n",
    "                = stats.pearsonr(a[:,ilat,ilon], b[:,ilat,ilon])\n",
    "    return [corrvalues, pvalues]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "corr_interannual = {}\n",
    "\n",
    "for iseason in ['am', 'jja']:\n",
    "    corr_interannual[iseason] = {}\n",
    "    for mod_name in ['vr', 'rcm']:\n",
    "        corr_interannual[iseason][mod_name]  = {}\n",
    "        corr_interannual[iseason][mod_name]['corr']    = \\\n",
    "            xr.corr(var_interannual[iseason]['obs'], var_interannual[iseason][mod_name], dim= 'year')\n",
    "        corr_scipy, pvalues_scipy = \\\n",
    "            scipy_count_corr_2d(var_interannual[iseason]['obs'].values, var_interannual[iseason][mod_name].values)\n",
    "        corr_interannual[iseason][mod_name]['pvalues'] = xr.DataArray(pvalues_scipy, coords = \\\n",
    "            corr_interannual[iseason][mod_name]['corr'].coords, name = 'pvalues')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 计算年纪均方根误差"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "rmse_interannual = {}\n",
    "\n",
    "for iseason in ['am', 'jja']:\n",
    "    rmse_interannual[iseason] = {}\n",
    "    for mod_name in ['vr','rcm']:\n",
    "        nyears = var_interannual[iseason][mod_name].year.shape[0]\n",
    "        rmse_temp = np.sqrt( ( (var_interannual[iseason][mod_name].values - var_interannual[iseason]['obs'].values)**2).sum(axis = 0) / nyears)\n",
    "        rmse_interannual[iseason][mod_name] = xr.DataArray(rmse_temp, coords = \\\n",
    "            corr_interannual[iseason][mod_name]['corr'].coords, name = 'rmse')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 绘图部分"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 调整cmap，去掉gist_ncar 中深蓝色的部分\n",
    "# https://stackoverflow.com/questions/18926031/how-to-extract-a-subset-of-a-colormap-as-a-new-colormap-in-matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import numpy as np\n",
    "import cmaps\n",
    "\n",
    "def truncate_colormap(cmap, minval=0.0, maxval=1.0, n=100):\n",
    "    new_cmap = colors.LinearSegmentedColormap.from_list(\n",
    "        'trunc({n},{a:.2f},{b:.2f})'.format(n=cmap.name, a=minval, b=maxval),\n",
    "        cmap(np.linspace(minval, maxval, n)))\n",
    "    return new_cmap\n",
    "\n",
    "arr = np.linspace(0, 50, 100).reshape((10, 10))\n",
    "fig, ax = plt.subplots(ncols=2)\n",
    "\n",
    "# cmap_corr     = plt.get_cmap('bwr')\n",
    "# cmap_corr     = cmaps.GMT_panoply\n",
    "cmap_corr     = cmaps.ncl_default\n",
    "cmap_rmse     = plt.get_cmap('gist_ncar')\n",
    "new_cmap_corr = truncate_colormap(cmap_corr, 0., 1.)\n",
    "new_cmap_rmse = truncate_colormap(cmap_rmse, 0.4, 1.)\n",
    "ax[0].imshow(arr, interpolation='nearest', cmap=cmap_corr)\n",
    "ax[1].imshow(arr, interpolation='nearest', cmap=new_cmap_rmse)\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 国内政区图的绘制\n",
    "# Load the border data, CN-border-La.dat is download from\n",
    "# https://gmt-china.org/data/CN-border-La.dat\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.io.shapereader as shpreader\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "cn_border_file = \"/m2data2/yycheng/data_stage/CN-border/CN-border_line/CN-border-La.dat\"\n",
    "with open(cn_border_file) as src:\n",
    "    context = src.read()\n",
    "    blocks = [cnt for cnt in context.split('>') if len(cnt) > 0]\n",
    "    borders = [np.fromstring(block, dtype=float, sep=' ') for block in blocks]\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 画图renew\n",
    "#### 2021.08.08\n",
    "cn_border_file + shapefile ，但是存在重叠，尝试消除掉China边界，但是其他邻国边界无法处理；\n",
    "#### 2021.08.09\n",
    "\n",
    "不使用cn_border_file ，使用shapefile + coast_line（proplot自带） 的办法\n",
    "\n",
    "shapefile有一些重叠，不绘制行政区\n",
    "\n",
    "shapefile重新进行绘制，考虑来自 domain_info 中测试的多个shape file中挑选出地资所（改变了prj方式之后就可以正常绘制，具体查看prj后缀文件）进行使用\n",
    "\n",
    "如果都使用环资所的全球、全国数据，那么是不会出现问题的\n",
    "\n",
    "#### 2021.08.13\n",
    "绘制相关性，使用hatch打点比较困难，这里直接考虑使用scatter打点，并且对过于密集的格点手动降低了密度 [::4] 散点大小约为1°"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# # 打点的方法\n",
    "# test_or = corr_interannual[iseason][mod_name]['pvalues'][::4,::4]\n",
    "# test = test_or < 0.1\n",
    "# scatter_test = np.argwhere(test.values)\n",
    "# # 找到正确的散点经纬度之后绘制\n",
    "# plt.scatter(lon[::4][ scatter_test[:,1][::4] ],lat[::4][ scatter_test[:,0][::4] ], s=0.1, color = 'k', marker='o')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# import proplot as plot\n",
    "from matplotlib import pyplot as plt\n",
    "import proplot as plot\n",
    "# ----- get filter vars coords-----\n",
    "\n",
    "lon = corr_interannual['am']['vr']['corr'].lon.values\n",
    "lat = corr_interannual['am']['vr']['corr'].lat.values\n",
    "\n",
    "#----- create plot -----\n",
    "fig, axs = plot.subplots(ncols=4 ,nrows=2, proj=('cyl'))\n",
    "m_contour_list = [] # 用于保存contour设置，后续设置colorbar使用\n",
    "\n",
    "#----- 添加海洋以及行政区划 -----\n",
    "##---- 直接绘图，从边界文件添加\n",
    "\n",
    "# for ax_ind in axs:\n",
    "# for line in borders:\n",
    "    # axs.plot(line[0::100], line[1::100], lw = 0.5, color='gray',transform=ccrs.Geodetic())\n",
    "    # axs.plot(line[0::10], line[1::10], lw = 0.4, color='black',transform=ccrs.Geodetic())\n",
    "##---- 使用shp文件添加\n",
    "    ## shapefile数据下载的位置：\n",
    "## http://gaohr.win/site/blogs/2017/2017-04-18-GIS-basic-data-of-China.html\n",
    "# world_border_shapefile = \"/m2data2/yycheng/data_stage/CN-border/World/country.shp\"\n",
    "river_border_shapefile =  \"/raid52/yycheng/MPAS/REFERENCE/MODEL_CONSTANT/R1/\" + \"hyd1_4l.shp\"\n",
    "southsea_shapefile     = \"/m2data2/yycheng/data_stage/CN-border/SouthSea/\" + \"southsea_island.shp\"\n",
    "ninelines_shapefile     = \"/m2data2/yycheng/data_stage/CN-border/SouthSea/\" + \"nine_lines.shp\"\n",
    "## 来源： 沛沛的诸省 + 诸岛\n",
    "bou24p_shapefile     = \"/m2data2/yycheng/data_stage/CN-border/peipeihelp/\" + \"bou2_4p.shp\"\n",
    "## 来源： https://www.resdc.cn/data.aspx?DATAID=200\n",
    "province_shapefile     = \"/m2data2/yycheng/data_stage/CN-border/CN-sheng/\" + \"change_proj_CN-sheng-A.shp\"\n",
    "\n",
    "for ax in axs:\n",
    "    # world     = shpreader.Reader(world_border_shapefile).geometries()\n",
    "    river     = shpreader.Reader(river_border_shapefile).geometries()\n",
    "    # bou24p    = shpreader.Reader(bou24p_shapefile).geometries()\n",
    "    ninelines = shpreader.Reader(ninelines_shapefile).geometries()\n",
    "    province  = shpreader.Reader(province_shapefile).geometries()\n",
    "    ax.add_geometries(river, ccrs.PlateCarree(), facecolor='none', edgecolor='b', linewidth=0.4, zorder=1)\n",
    "    # ax.add_geometries(world, ccrs.PlateCarree(), facecolor='none', edgecolor='k', linewidth=0.4, zorder=1)\n",
    "    # ax.add_geometries(bou24p, ccrs.PlateCarree(), facecolor='none', edgecolor='k', linewidth=0.6, zorder=1) # 沛沛map\n",
    "    ax.add_geometries(province, ccrs.PlateCarree(), facecolor='none', edgecolor='k', linewidth=0.6, zorder=1) # 地资所\n",
    "    ax.add_geometries(ninelines, ccrs.PlateCarree(), facecolor='none', edgecolor='k', linewidth=0.6, zorder=1)\n",
    "\n",
    "#----- colorbar ticks 统一设置 -----\n",
    "# cmap = 'gist_ncar'\n",
    "# cmap = new_cmap\n",
    "# cmap = cmap_data\n",
    "\n",
    "corr_ticks = np.linspace(-0.5,1, 16)\n",
    "rmse_ticks = np.linspace(0, 25, 26)\n",
    "rmse_ticks = np.concatenate((np.linspace(0,10,21), [12,14,16,18,20,25]), axis=0)\n",
    "# print(\"----- tick levels is : \" + str(mean_ticks))\n",
    "\n",
    "# plot contourf and titile axs\n",
    "axs[0,:].format(ltitle = 'AM')\n",
    "axs[1,:].format(ltitle = 'JJA')\n",
    "axs[:,0].format(title='VR')\n",
    "axs[:,1].format(title='RCM')\n",
    "axs[:,2].format(title='VR')\n",
    "axs[:,3].format(title='RCM')\n",
    "axs[0,1].format(rtitle='CORR')\n",
    "axs[0,3].format(rtitle='RMSE')\n",
    "\n",
    "for season_ind, season_name in enumerate(['am','jja']):\n",
    "    for mod_ind, mod_name in enumerate(['vr','rcm']):\n",
    "        # corr\n",
    "        m_corr  = axs[season_ind, mod_ind].contourf(lon, lat, corr_interannual[season_name][mod_name]['corr'].values,\\\n",
    "        levels=corr_ticks,cmap=new_cmap_corr, norm = \"midpoint\")\n",
    "        # 绘制散点\n",
    "        # 需要将原本密集的格点散点减少 (::4) 然后找到减少后的经纬度lon[::4] 进行散点的绘制\n",
    "        scatter_test = np.argwhere((corr_interannual[season_name][mod_name]['pvalues'][::4,::4]<0.05).values)\n",
    "        axs[season_ind, mod_ind].scatter(lon[::4][scatter_test[:,1]],lat[::4][scatter_test[:,0]], s=0.15, color = 'k', marker='o')\n",
    "\n",
    "        # rmse\n",
    "        m_rmse  = axs[season_ind, mod_ind+2].contourf(lon, lat, rmse_interannual[season_name][mod_name].values,\\\n",
    "        levels=rmse_ticks,cmap=new_cmap_rmse)\n",
    "\n",
    "# m_corr = axs[mod_ind+4].contourf(lon, lat, corr_interannual['jja'][mod_name]['corr'].values,\\\n",
    "# levels=mean_ticks,cmap=new_cmap_corr)\n",
    "# scatter_test = np.argwhere((corr_interannual['jja'][mod_name]['pvalues'][::4,::4]<0.05).values)\n",
    "# axs[mod_ind+4].scatter(lon[::4][ scatter_test[:,1] ], lat[::4][ scatter_test[:,0] ], s=0.15, color = 'k', marker='o')\n",
    "\n",
    "\n",
    "# m_rmse  = axs[mod_ind+3].contourf(lon, lat, rmse_interannual['jja'][mod_name].values,\\\n",
    "# levels=rmse_ticks,cmap=new_cmap_corr)\n",
    "\n",
    "#----- add color bar-----\n",
    "# fig.colorbar(m_overlay, loc='b', cmap=cmap, width=0.1)\n",
    "\n",
    "fig.colorbar(m_corr, loc='b', width=0.1,cols = (1,2),\n",
    "ticklabelsize=5,ticks=corr_ticks, title='corrleation')\n",
    "\n",
    "fig.colorbar(m_rmse, loc='b', width=0.1,cols = (3,4),\n",
    "ticklabelsize=5,ticks=rmse_ticks, title='RMSE')\n",
    "\n",
    "\n",
    "# axs[0].colorbar(m_mean, loc='b', width=0.1,\n",
    "# ticklabelsize=5,ticks=mean_ticks)\n",
    "\n",
    "# axs[1].colorbar(m_idctn, loc='b', width=0.1,\n",
    "# ticklabelsize=5,ticks=idctn_ticks)\n",
    "\n",
    "# axs[2].colorbar(m_idctn_diff, loc='b',width=0.1,\n",
    "# ticklabelsize=5,ticks=diff_ticks)\n",
    "\n",
    "\n",
    "# ----- format setting -----\n",
    "axs.format(\n",
    "abc=True,\n",
    "abcloc = 'ul',\n",
    "#----- 地图底图设置 -----\n",
    "# reso = 'x-hi',\n",
    "reso = 'med',\n",
    "# coast = False,\n",
    "coast = True,\n",
    "coastlinewidth = 0.4,\n",
    "borders = False,\n",
    "lakes = False,\n",
    "land  = False,\n",
    "ocean = False,\n",
    "# cartopyautoextent = True, \n",
    "# borderslinewidth=.5,\n",
    "labels = True,\n",
    "longrid  = True,\n",
    "latgrid  = True,\n",
    "#-----GEO axis-----\n",
    "lonlim=(70, 140), latlim=(5, 60),\n",
    "gridlabelsize = 5,\n",
    "gridminor = True,\n",
    "lonlocator = np.arange(70,142,10),\n",
    "latlocator = np.arange(5,60+2,10),\n",
    "lonminorlocator = np.arange(70,140+2,2),\n",
    "latminorlocator = np.arange(5,60+2,2),\n",
    "#-----line label-----\n",
    "# linewidth = 0.5,\n",
    "# suptitle=\"3000km-2000km bandpass 500hPa height(1998-06 timemean)\",\n",
    "suptitle=\"interannual TCC & RMSE\",\n",
    ")\n",
    "\n",
    "#----- save figure -----\n",
    "fig.patch.set_facecolor('white')\n",
    "plt.savefig('./output_pic/pre_corr_98-17_pplt_0913.png', dpi=600, facecolor= \"white\")\n",
    "# plt.savefig('./output_pic/hgt_idctn.png', dpi=300, facecolor= \"white\")"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.2",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.2 64-bit ('proplot0528': conda)"
  },
  "interpreter": {
   "hash": "da0469cb1653dac5810650c6f9c12d7c46a389e85e448c305f1477fdb1af5288"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}